{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aadhaar Data Cleaning & Preparation\n",
    "\n",
    "Welcome! This notebook is designed to help to process and clean Aadhaar datasets (Biometric, Demographic, and Enrolment) easily.\n",
    "\n",
    "### What this notebook does:\n",
    "1. **Loads** data from multiple CSV files.\n",
    "2. **Merges** them into one large dataset for each category.\n",
    "3. **Cleans** the state names (fixes spelling mistakes like 'Telengana' -> 'Telangana').\n",
    "4. **Saves** the clean data to new files for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import display  # To show DataFrames nicely\n",
    "\n",
    "# Display settings to show all columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Configuration\n",
    "We define a list of **correct state names** and a **dictionary** to fix common spelling errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRECT SPELLING -> Standard Name\n",
    "STATE_MAPPING = {\n",
    "    'westbengal': 'West Bengal',\n",
    "    'west bangal': 'West Bengal',\n",
    "    'west bengli': 'West Bengal',\n",
    "    'wb': 'West Bengal',\n",
    "    'west  bengal': 'West Bengal',\n",
    "    'odisha': 'Odisha',\n",
    "    'orissa': 'Odisha',\n",
    "    'pondicherry': 'Puducherry',\n",
    "    'puducherry': 'Puducherry',\n",
    "    'uttaranchal': 'Uttarakhand',\n",
    "    'uttarakhand': 'Uttarakhand',\n",
    "    'jammu & kashmir': 'Jammu & Kashmir',\n",
    "    'jammu and kashmir': 'Jammu & Kashmir',\n",
    "    'andaman & nicobar islands': 'Andaman & Nicobar Islands',\n",
    "    'andaman and nicobar islands': 'Andaman & Nicobar Islands',\n",
    "    'chhatisgarh': 'Chhattisgarh',\n",
    "    'chhattisgarh': 'Chhattisgarh',\n",
    "    'tamilnadu': 'Tamil Nadu',\n",
    "    'tamil nadu': 'Tamil Nadu',\n",
    "    'telangana': 'Telangana',\n",
    "    'dadra and nagar haveli': 'Dadra & Nagar Haveli and Daman & Diu',\n",
    "    'dadra & nagar haveli': 'Dadra & Nagar Haveli and Daman & Diu',\n",
    "    'daman and diu': 'Dadra & Nagar Haveli and Daman & Diu',\n",
    "    'daman & diu': 'Dadra & Nagar Haveli and Daman & Diu',\n",
    "    'dadra and nagar haveli and daman and diu': 'Dadra & Nagar Haveli and Daman & Diu',\n",
    "    'the dadra and nagar haveli and daman and diu': 'Dadra & Nagar Haveli and Daman & Diu'\n",
    "}\n",
    "\n",
    "# List of valid states to keep (Anything else will be removed as garbage data)\n",
    "VALID_STATES = {\n",
    "    'Andhra Pradesh', 'Arunachal Pradesh', 'Assam', 'Bihar', 'Chhattisgarh',\n",
    "    'Goa', 'Gujarat', 'Haryana', 'Himachal Pradesh', 'Jharkhand', 'Karnataka',\n",
    "    'Kerala', 'Madhya Pradesh', 'Maharashtra', 'Manipur', 'Meghalaya', 'Mizoram',\n",
    "    'Nagaland', 'Odisha', 'Punjab', 'Rajasthan', 'Sikkim', 'Tamil Nadu',\n",
    "    'Telangana', 'Tripura', 'Uttar Pradesh', 'Uttarakhand', 'West Bengal',\n",
    "    'Andaman & Nicobar Islands', 'Chandigarh', 'Dadra & Nagar Haveli and Daman & Diu',\n",
    "    'Delhi', 'Jammu & Kashmir', 'Ladakh', 'Lakshadweep', 'Puducherry'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Helper Functions\n",
    "These functions handle the repetitive work of loading files and cleaning the state column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_merge(file_list, output_raw_path=None):\n",
    "    \"\"\"Loads multiple CSV files and merges them into a single DataFrame.\"\"\"\n",
    "    print(f\"Loading {len(file_list)} files...\")\n",
    "    dfs = []\n",
    "    for f in file_list:\n",
    "        if os.path.exists(f):\n",
    "            print(f\"  - Reading {f}\")\n",
    "            dfs.append(pd.read_csv(f))\n",
    "        else:\n",
    "            print(f\"  - Warning: File not found: {f}\")\n",
    "    \n",
    "    if not dfs:\n",
    "        print(\"No files loaded!\")\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    merged = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "    print(f\"Total rows loaded: {len(merged)}\")\n",
    "    \n",
    "    if output_raw_path:\n",
    "        merged.to_csv(output_raw_path, index=False)\n",
    "        print(f\"Saved raw combined data to: {output_raw_path}\")\n",
    "        \n",
    "    return merged\n",
    "\n",
    "def clean_state_column(df, state_col='state'):\n",
    "    \"\"\"Standardizes state names and removes invalid entries.\"\"\"\n",
    "    if df.empty: return df\n",
    "    \n",
    "    print(\"Cleaning state column...\")\n",
    "    initial_count = len(df)\n",
    "    \n",
    "    # 1. Basic cleanup (remove spaces, lowercase)\n",
    "    df[state_col] = df[state_col].astype(str).str.strip().str.lower()\n",
    "    df[state_col] = df[state_col].str.replace(r'\\s+', ' ', regex=True)\n",
    "    \n",
    "    # 2. Fix spelling using our mapping\n",
    "    df[state_col] = df[state_col].replace(STATE_MAPPING)\n",
    "    \n",
    "    # 3. Capitalize nicely (Title Case)\n",
    "    df[state_col] = df[state_col].str.title()\n",
    "    \n",
    "    # 4. Remove invalid states\n",
    "    df = df[df[state_col].isin(VALID_STATES)]\n",
    "    \n",
    "    final_count = len(df)\n",
    "    rows_dropped = initial_count - final_count\n",
    "    print(f\"Dropped {rows_dropped} rows with invalid state names.\")\n",
    "    print(f\"Remaining rows: {final_count}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Step 3: Biometric Data Processing\n",
    "Files processed: `api_data_aadhar_biometric_0_500000` to `api_data_aadhar_biometric_1500000_1861108`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 4 files...\n",
      "  - Reading ../data/raw/api_data_aadhar_biometric/api_data_aadhar_biometric_0_500000.csv\n",
      "  - Reading ../data/raw/api_data_aadhar_biometric/api_data_aadhar_biometric_500000_1000000.csv\n",
      "  - Reading ../data/raw/api_data_aadhar_biometric/api_data_aadhar_biometric_1000000_1500000.csv\n",
      "  - Reading ../data/raw/api_data_aadhar_biometric/api_data_aadhar_biometric_1500000_1861108.csv\n",
      "Total rows loaded: 1861108\n",
      "Saved raw combined data to: ../data/processed/combined_biometric.csv\n",
      "Cleaning state column...\n",
      "Dropped 1325 rows with invalid state names.\n",
      "Remaining rows: 1859783\n",
      "Preview of Cleaned Biometric Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>district</th>\n",
       "      <th>pincode</th>\n",
       "      <th>bio_age_5_17</th>\n",
       "      <th>bio_age_17_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-03-2025</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>Mahendragarh</td>\n",
       "      <td>123029</td>\n",
       "      <td>280</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-03-2025</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>Madhepura</td>\n",
       "      <td>852121</td>\n",
       "      <td>144</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-03-2025</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>Punch</td>\n",
       "      <td>185101</td>\n",
       "      <td>643</td>\n",
       "      <td>1091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-03-2025</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>Bhojpur</td>\n",
       "      <td>802158</td>\n",
       "      <td>256</td>\n",
       "      <td>980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-03-2025</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>Madurai</td>\n",
       "      <td>625514</td>\n",
       "      <td>271</td>\n",
       "      <td>815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date            state      district  pincode  bio_age_5_17  \\\n",
       "0  01-03-2025          Haryana  Mahendragarh   123029           280   \n",
       "1  01-03-2025            Bihar     Madhepura   852121           144   \n",
       "2  01-03-2025  Jammu & Kashmir         Punch   185101           643   \n",
       "3  01-03-2025            Bihar       Bhojpur   802158           256   \n",
       "4  01-03-2025       Tamil Nadu       Madurai   625514           271   \n",
       "\n",
       "   bio_age_17_  \n",
       "0          577  \n",
       "1          369  \n",
       "2         1091  \n",
       "3          980  \n",
       "4          815  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biometric data saved to 'combined_biometric_cleaned.csv'\n"
     ]
    }
   ],
   "source": [
    "# 1. Define input files\n",
    "bio_files = [\n",
    "    \"../data/raw/api_data_aadhar_biometric/api_data_aadhar_biometric_0_500000.csv\",\n",
    "    \"../data/raw/api_data_aadhar_biometric/api_data_aadhar_biometric_500000_1000000.csv\",\n",
    "    \"../data/raw/api_data_aadhar_biometric/api_data_aadhar_biometric_1000000_1500000.csv\",\n",
    "    \"../data/raw/api_data_aadhar_biometric/api_data_aadhar_biometric_1500000_1861108.csv\"\n",
    "]\n",
    "\n",
    "# 2. Load and Merge\n",
    "bio_df = load_and_merge(bio_files, \"../data/processed/combined_biometric.csv\")\n",
    "\n",
    "# 3. Clean\n",
    "bio_df = clean_state_column(bio_df)\n",
    "print(\"Preview of Cleaned Biometric Data:\")\n",
    "display(bio_df.head())\n",
    "\n",
    "# 4. Save\n",
    "bio_df.to_csv(\"../data/processed/combined_biometric_cleaned.csv\", index=False)\n",
    "print(\"Biometric data saved to 'combined_biometric_cleaned.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Step 4: Demographic Data Processing\n",
    "Files processed: `api_data_aadhar_demographic_0_500000` to `api_data_aadhar_demographic_2000000_2071700`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 5 files...\n",
      "  - Reading ../data/raw/api_data_aadhar_demographic/api_data_aadhar_demographic_0_500000.csv\n",
      "  - Reading ../data/raw/api_data_aadhar_demographic/api_data_aadhar_demographic_500000_1000000.csv\n",
      "  - Reading ../data/raw/api_data_aadhar_demographic/api_data_aadhar_demographic_1000000_1500000.csv\n",
      "  - Reading ../data/raw/api_data_aadhar_demographic/api_data_aadhar_demographic_1500000_2000000.csv\n",
      "  - Reading ../data/raw/api_data_aadhar_demographic/api_data_aadhar_demographic_2000000_2071700.csv\n",
      "Total rows loaded: 2071700\n",
      "Saved raw combined data to: ../data/processed/combined_demographic.csv\n",
      "Cleaning state column...\n",
      "Dropped 1640 rows with invalid state names.\n",
      "Remaining rows: 2070060\n",
      "Preview of Cleaned Demographic Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>district</th>\n",
       "      <th>pincode</th>\n",
       "      <th>demo_age_5_17</th>\n",
       "      <th>demo_age_17_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-03-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Gorakhpur</td>\n",
       "      <td>273213</td>\n",
       "      <td>49</td>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-03-2025</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Chittoor</td>\n",
       "      <td>517132</td>\n",
       "      <td>22</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-03-2025</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>Rajkot</td>\n",
       "      <td>360006</td>\n",
       "      <td>65</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-03-2025</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Srikakulam</td>\n",
       "      <td>532484</td>\n",
       "      <td>24</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-03-2025</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>Udaipur</td>\n",
       "      <td>313801</td>\n",
       "      <td>45</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date           state    district  pincode  demo_age_5_17  \\\n",
       "0  01-03-2025   Uttar Pradesh   Gorakhpur   273213             49   \n",
       "1  01-03-2025  Andhra Pradesh    Chittoor   517132             22   \n",
       "2  01-03-2025         Gujarat      Rajkot   360006             65   \n",
       "3  01-03-2025  Andhra Pradesh  Srikakulam   532484             24   \n",
       "4  01-03-2025       Rajasthan     Udaipur   313801             45   \n",
       "\n",
       "   demo_age_17_  \n",
       "0           529  \n",
       "1           375  \n",
       "2           765  \n",
       "3           314  \n",
       "4           785  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographic data saved to 'combined_demographic_cleaned.csv'\n"
     ]
    }
   ],
   "source": [
    "# 1. Define input files\n",
    "demo_files = [\n",
    "    \"../data/raw/api_data_aadhar_demographic/api_data_aadhar_demographic_0_500000.csv\",\n",
    "    \"../data/raw/api_data_aadhar_demographic/api_data_aadhar_demographic_500000_1000000.csv\",\n",
    "    \"../data/raw/api_data_aadhar_demographic/api_data_aadhar_demographic_1000000_1500000.csv\",\n",
    "    \"../data/raw/api_data_aadhar_demographic/api_data_aadhar_demographic_1500000_2000000.csv\",\n",
    "    \"../data/raw/api_data_aadhar_demographic/api_data_aadhar_demographic_2000000_2071700.csv\"\n",
    "]\n",
    "\n",
    "# 2. Load and Merge\n",
    "demo_df = load_and_merge(demo_files, \"../data/processed/combined_demographic.csv\")\n",
    "\n",
    "# 3. Clean\n",
    "demo_df = clean_state_column(demo_df)\n",
    "print(\"Preview of Cleaned Demographic Data:\")\n",
    "display(demo_df.head())\n",
    "\n",
    "# 4. Save\n",
    "demo_df.to_csv(\"../data/processed/combined_demographic_cleaned.csv\", index=False)\n",
    "print(\"Demographic data saved to 'combined_demographic_cleaned.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Step 5: Enrolment Data Processing\n",
    "Files processed: `api_data_aadhar_enrolment_0_500000` to `api_data_aadhar_enrolment_1000000_1006029`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 3 files...\n",
      "  - Reading ../data/raw/api_data_aadhar_enrolment/api_data_aadhar_enrolment_0_500000.csv\n",
      "  - Reading ../data/raw/api_data_aadhar_enrolment/api_data_aadhar_enrolment_500000_1000000.csv\n",
      "  - Reading ../data/raw/api_data_aadhar_enrolment/api_data_aadhar_enrolment_1000000_1006029.csv\n",
      "Total rows loaded: 1006029\n",
      "Saved raw combined data to: ../data/processed/combined_enrolment.csv\n",
      "Cleaning state column...\n",
      "Dropped 438 rows with invalid state names.\n",
      "Remaining rows: 1005591\n",
      "Preview of Cleaned Enrolment Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>district</th>\n",
       "      <th>pincode</th>\n",
       "      <th>age_0_5</th>\n",
       "      <th>age_5_17</th>\n",
       "      <th>age_18_greater</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02-03-2025</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>East Khasi Hills</td>\n",
       "      <td>793121</td>\n",
       "      <td>11</td>\n",
       "      <td>61</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bengaluru Urban</td>\n",
       "      <td>560043</td>\n",
       "      <td>14</td>\n",
       "      <td>33</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Kanpur Nagar</td>\n",
       "      <td>208001</td>\n",
       "      <td>29</td>\n",
       "      <td>82</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Aligarh</td>\n",
       "      <td>202133</td>\n",
       "      <td>62</td>\n",
       "      <td>29</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bengaluru Urban</td>\n",
       "      <td>560016</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date          state          district  pincode  age_0_5  age_5_17  \\\n",
       "0  02-03-2025      Meghalaya  East Khasi Hills   793121       11        61   \n",
       "1  09-03-2025      Karnataka   Bengaluru Urban   560043       14        33   \n",
       "2  09-03-2025  Uttar Pradesh      Kanpur Nagar   208001       29        82   \n",
       "3  09-03-2025  Uttar Pradesh           Aligarh   202133       62        29   \n",
       "4  09-03-2025      Karnataka   Bengaluru Urban   560016       14        16   \n",
       "\n",
       "   age_18_greater  \n",
       "0              37  \n",
       "1              39  \n",
       "2              12  \n",
       "3              15  \n",
       "4              21  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enrolment data saved to 'combined_enrolment_cleaned.csv'\n"
     ]
    }
   ],
   "source": [
    "# 1. Define input files\n",
    "enrol_files = [\n",
    "    \"../data/raw/api_data_aadhar_enrolment/api_data_aadhar_enrolment_0_500000.csv\",\n",
    "    \"../data/raw/api_data_aadhar_enrolment/api_data_aadhar_enrolment_500000_1000000.csv\",\n",
    "    \"../data/raw/api_data_aadhar_enrolment/api_data_aadhar_enrolment_1000000_1006029.csv\"\n",
    "]\n",
    "\n",
    "# 2. Load and Merge\n",
    "enrol_df = load_and_merge(enrol_files, \"../data/processed/combined_enrolment.csv\")\n",
    "\n",
    "# 3. Clean\n",
    "enrol_df = clean_state_column(enrol_df)\n",
    "print(\"Preview of Cleaned Enrolment Data:\")\n",
    "display(enrol_df.head())\n",
    "\n",
    "# 4. Save\n",
    "enrol_df.to_csv(\"../data/processed/combined_enrolment_cleaned.csv\", index=False)\n",
    "print(\"Enrolment data saved to 'combined_enrolment_cleaned.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---\n",
    "## Step 6: Backend Data Preparation for Aadhaar Trends Dashboard\n",
    "This script implements a robust ETL (Extract, Transform, Load) workflow to prepare raw Aadhaar transaction logs \n",
    "for downstream analysis and visualization. It handles data standardization, temporal parsing, and feature \n",
    "engineering to create a unified 'Master Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "master_data.csv created successfully and ready for Tableau!\n"
     ]
    }
   ],
   "source": [
    "# 1. LOAD DATASETS\n",
    "\n",
    "enrol = pd.read_csv(\"../data/processed/combined_enrolment_cleaned.csv\")\n",
    "bio   = pd.read_csv(\"../data/processed/combined_biometric_cleaned.csv\")\n",
    "demo  = pd.read_csv(\"../data/processed/combined_demographic_cleaned.csv\")\n",
    "\n",
    "# 2. CLEAN TEXT COLUMNS\n",
    "\n",
    "for df in [enrol, bio, demo]:\n",
    "    df['state'] = df['state'].astype(str).str.strip().str.title()\n",
    "    df['district'] = df['district'].astype(str).str.strip().str.title()\n",
    "    df['pincode'] = df['pincode'].astype(str).str.strip()\n",
    "\n",
    "# 3. FIX DATE FORMAT (DD-MM-YYYY)\n",
    "\n",
    "enrol['date'] = pd.to_datetime(enrol['date'], dayfirst=True, errors='coerce')\n",
    "bio['date']   = pd.to_datetime(bio['date'], dayfirst=True, errors='coerce')\n",
    "demo['date']  = pd.to_datetime(demo['date'], dayfirst=True, errors='coerce')\n",
    "\n",
    "# 4. MERGE DATASETS\n",
    "\n",
    "df = enrol.merge(\n",
    "    bio,\n",
    "    on=['date', 'state', 'district', 'pincode'],\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "df = df.merge(\n",
    "    demo,\n",
    "    on=['date', 'state', 'district', 'pincode'],\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "\n",
    "# 5. HANDLE MISSING VALUES\n",
    "\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# 6. FEATURE ENGINEERING\n",
    "\n",
    "\n",
    "# Total Aadhaar Enrolment\n",
    "df['Total_Enrolment'] = (\n",
    "    df['age_0_5'] +\n",
    "    df['age_5_17'] +\n",
    "    df['age_18_greater']\n",
    ")\n",
    "\n",
    "# Total Aadhaar Updates\n",
    "df['Total_Updates'] = (\n",
    "    df['bio_age_5_17'] +\n",
    "    df['bio_age_17_'] +\n",
    "    df['demo_age_5_17'] +\n",
    "    df['demo_age_17_']\n",
    ")\n",
    "\n",
    "# Youth Activity Share \n",
    "df['Youth_Share'] = np.where(\n",
    "    (df['Total_Enrolment'] + df['Total_Updates']) > 0,\n",
    "    (\n",
    "        (df['age_5_17'] + df['bio_age_5_17'] + df['demo_age_5_17']) /\n",
    "        (df['Total_Enrolment'] + df['Total_Updates'])\n",
    "    ) * 100,\n",
    "    0\n",
    ")\n",
    "\n",
    "# 7. OPTIONAL: SORT DATA\n",
    "\n",
    "df.sort_values(by=['date', 'state', 'district'], inplace=True)\n",
    "\n",
    "\n",
    "# 8. SAVE FINAL DATASET\n",
    "\n",
    "df.to_csv(\"../data/processed/master_data.csv\", index=False)\n",
    "\n",
    "print(\"master_data.csv created successfully and ready for Tableau!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
